{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "\n",
    "from datasets.squidle_data import SquidleData\n",
    "from datasets.squidle_connection import SquidleAnnotator, SquidleConnection\n",
    "from sqapi.api import SQAPI\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 0. Setup config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b56259e195f62153"
  },
  {
   "cell_type": "code",
   "source": [
    "### Config and squidle access setup\n",
    "config = \"squidle_hand_target.yaml\"\n",
    "abs_config_dir=os.path.abspath(\"../config/dataset\")\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    opt = compose(config_name=config)\n",
    "    #print(OmegaConf.to_yaml(opt, resolve=True))\n",
    "#print(opt)\n",
    "OmegaConf.set_struct(opt, False)\n",
    "\n",
    "dataset = SquidleData(opt, semi_supervised=True)\n",
    "sq_annotator = SquidleAnnotator(api_key=opt.annotate_api_token, host=opt.url)\n",
    "sq_annotator = SquidleAnnotator(api_key=opt.api_token, host=opt.url)\n",
    "squidle_connection = SquidleConnection(sqapi=sq_annotator.sqapi)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8239dd8beb45ddf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Get annotations\n",
    "\n",
    "\n",
    "Red Cup sponge not in [5862, 5863, 12745, 12750, 12747, 12739]\n",
    "\n",
    "Counter({13249: 919, 5861: 121, 12749: 116, 12748: 109, 12737: 100, 12751: 99, 10567: 36, 10566: 26, 7933: 24, 12339: 23, 10570: 19, 7914: 18, 7925: 18, 5853: 16, 466: 14, 12740: 14, 5852: 13, 7927: 12, 8126: 12, 7932: 11, 11625: 10, 12444: 10, 11637: 9, 7987: 8, 4003: 7, 7978: 7, 10546: 6, 10862: 6, 10880: 6, 11609: 6, 7940: 5, 8048: 5, 7931: 4, 8127: 4, 9472: 4, 10547: 4, 3418: 3, 5869: 3, 7939: 3, 7984: 3, 10870: 3, 3988: 2, 7770: 2, 10885: 2, 11186: 2, 442: 1, 2133: 1, 7929: 1, 7937: 1, 7938: 1, 7941: 1, 7942: 1, 8100: 1, 8123: 1, 10548: 1, 10553: 1})\n",
    "Counter({7111: 1238, 13288: 540, 7104: 77})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d08972661aac33bd"
  },
  {
   "cell_type": "code",
   "source": [
    "label_ids = list(dataset.opt.squidle_mapping)\n",
    "#label_ids = [13450]\n",
    "annotation_set_ids = list(dataset.opt.annotation_set_ids) if dataset.opt.annotation_set_ids is not None else []\n",
    "#annotation_set_ids = [5862, 5863, 12745, 12750, 12747, 12739] # train\n",
    "exclude_annotation_set_ids = dataset.opt.exclude_annotation_set_ids if dataset.opt.exclude_annotation_set_ids is not None else []\n",
    "#annotation_set_ids = [10827, 10829] # test\n",
    "#annotation_set_ids = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8ad77b12410071b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "annotation_list = dataset.squidle_connection.get_all_annotations_from_set(annotation_set_ids, label_ids=label_ids,\n",
    "                                                              include_annotation_sets=True,\n",
    "                                                              exclude_annotation_sets=list(set(dataset.opt.needs_review_annotation_set_ids) |\n",
    "                                                                          set(exclude_annotation_set_ids)),\n",
    "                                                              results_per_page=500)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4f8341312acee91",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "asi = list(set(dataset.opt.needs_review_annotation_set_ids) |\n",
    "           set(exclude_annotation_set_ids))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d826346673c4769",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset.squidle_connection.sqapi.get(f\"/api/annotation_set/13308\").execute().json())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be304940b69b5b87",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Run this if you're excluding annotation sets.\n",
    "annotation_list +=  dataset.squidle_connection.get_all_annotations_from_set(list(dataset.opt.needs_review_annotation_set_ids),\n",
    "                                                                       label_ids=label_ids,\n",
    "                                                                       include_annotation_sets=True,\n",
    "                                                                       needs_review=True,\n",
    "                                                                       results_per_page=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ed5937a558b9f65",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Ensure the training data (semi/excluding test/val annotation_sets) does not have any media from them.\n",
    "  - 10820 # 4 handfish\n",
    "  - 10827 # 4 handfish\n",
    "  - 10829 # 6 handfish\n",
    "  - 10818 # 1 handfish\n",
    "  - 10819 # 1 handfish\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "889fd3582de1ef10"
  },
  {
   "cell_type": "code",
   "source": [
    "excluded_media_collection_ids = []\n",
    "excluded_media = []\n",
    "#annotation_set_ids = [10829, 10819, 10818, 10820, 10827]\n",
    "annotation_set_ids = list(set([a['annotation_set_id'] for a in annotation_list]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df125b994b3ffca6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "media_id_dict = {}\n",
    "#annotation_set_ids = [8103]\n",
    "for asi in annotation_set_ids:\n",
    "    media_collection_id = dataset.squidle_connection.sqapi.get(f\"/api/annotation_set/{asi}\").execute().json()\n",
    "    media_collection_id = media_collection_id['media_collection']['id']\n",
    "    excluded_media_collection_ids.append(media_collection_id)\n",
    "    page = 1\n",
    "    request = sq_annotator.sqapi.get(\"/api/media\",\n",
    "                                     page=page, results_per_page=1000)\n",
    "    request.filter(name=\"media_collection_media\", op=\"any\",\n",
    "                   val={'name': \"media_collection_id\", 'op': 'eq', 'val': media_collection_id})\n",
    "    result = request.execute().json()\n",
    "    for m in result['objects']:\n",
    "        media_id_dict[m['id']] = m\n",
    "    excluded_media += [m['id'] for m in result['objects']]\n",
    "    print(f\"Total pages {result['total_pages']}\")\n",
    "    while page < result['total_pages']:\n",
    "        page += 1\n",
    "        request = sq_annotator.sqapi.get(\"/api/media\",\n",
    "                                         page=page, results_per_page=1000)\n",
    "        request.filter(name=\"media_collection_media\", op=\"any\",\n",
    "                       val={'name': \"media_collection_id\", 'op': 'eq', 'val': media_collection_id})\n",
    "        result = request.execute().json()\n",
    "        for m in result['objects']:\n",
    "            media_id_dict[m['id']] = m        \n",
    "        excluded_media += [m['id'] for m in result['objects']]        \n",
    "media_ids = list(set([a['point']['media_id'] for a in annotation_list]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c6511f52b0c49ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Get media_items for annotation_list\n",
    "page = 1\n",
    "request = sq_annotator.sqapi.get(\"/api/media\",\n",
    "                                 page=page, results_per_page=1000)\n",
    "request.filter(name=\"annotations\", op=\"any\",\n",
    "               val={'name': \"id\", 'op': 'in', 'val': list(set([a['point']['id'] for a in annotation_list]))})\n",
    "result = request.execute().json()\n",
    "media_id_dict = {m['id']: m for m in result['objects']}    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1383952bab6f2bb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "annotation_media_id_dict = defaultdict(list)\n",
    "for a in annotation_list:\n",
    "    media_id = a['point']['media_id']\n",
    "    annotation_media_id_dict[media_id].append(a)\n",
    "    if len(annotation_media_id_dict[media_id]) > 1:\n",
    "        print(media_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc7a35b877959097",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "deployment_counter = []\n",
    "for a_media_id in annotation_media_id_dict.keys():\n",
    "    d_id = media_id_dict[a_media_id]['deployment_id']\n",
    "    d_key = media_id_dict[a_media_id]['deployment']['key']\n",
    "    deployment_counter.append(f\"{d_id}_{d_key}\")\n",
    "\n",
    "deployment_counter = Counter(deployment_counter)\n",
    "for d in sorted(deployment_counter):\n",
    "    print(d, deployment_counter[d])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8470bcd8ea699229",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "LOCKED Test15 - 42 images from deployment 11682 and ahead (ie r20210617_033152_SS18_TF_NPZ_04_reversed 2)\n",
    "train85 - everything before 20210617 - 242 annotations\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c392c361fa34420"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "train, test = [], []\n",
    "for a in annotation_list_orig:\n",
    "    media_id = a['point']['media_id']\n",
    "    if media_id_dict[media_id]['deployment_id'] >= 11676:\n",
    "        test.append(a)\n",
    "    else:\n",
    "        train.append(a)\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52952ccac79a90e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "clean_annotation_list = []\n",
    "for a in annotation_list:\n",
    "    media_id = a['point']['media_id']\n",
    "    if media_id not in excluded_media:\n",
    "        clean_annotation_list.append(a)\n",
    "    else:\n",
    "        print(f\"Removing {media_id}\")\n",
    "        \n",
    "annotation_list = clean_annotation_list\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95a7ef18f9f97d65",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Create media_collection and annotation_set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7945f617adaff947"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Creating random selsections of training data\n",
    "Create 4 * 50 random selections plus 1 X 41 images for validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deeff9cbd9992350"
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def findElements(lst1, lst2):\n",
    "    return list(np.array(lst1)[lst2])\n",
    "selection = [i for i in range(len(train))]\n",
    "random.shuffle(selection)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ff90e904455fa2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "val = selection[0:41]\n",
    "train_1 = selection[41:91]\n",
    "train_2 = selection[91:141]\n",
    "train_3 = selection[141:191]\n",
    "train_4 = selection[191:241]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0b1ad2a95f6ce7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "set(val).intersection(set(train_3))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61a6480b5d48a7c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#original_query_annotation_list = annotation_list\n",
    "annotation_list = findElements(train, train_4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83f2661e7121cbeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "description = f\"Media and annotations for deployments including and before 11671_r20210614_222648_SS07_TF_NPZ_06 6  from annotation sets {set([a['annotation_set_id'] for a in annotation_list])}\"\n",
    "description = \"Media and annotations for all unique handfish detections by either human or AI.\"\n",
    "#description = f\"Random selection of n=50 handfish annotations v4 from Train 85pc dataset (13373) for training\"\n",
    "name = \"Handfish Detections - Human and AI generated\"\n",
    "group_id = 358"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a7872e6b3d5520",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "media_collection_id = sq_annotator.create_media_collection(name=name, description=description)\n",
    "print(media_collection_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa053903bc4bc314",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Add media to collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "300b7e64c7f5d655"
  },
  {
   "cell_type": "code",
   "source": [
    "# ADDING MEDIA to collection\n",
    "media_ids = list(set([a['point']['media_id'] for a in objs]))\n",
    "sq_annotator.add_media_to_collection(media_collection_id, media_ids)\n",
    "print(\"Finished!!!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed78f9ea2de9cc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ONEOFF - Used to add additional media items for annotation for Helico fish\n",
    "media_collection_id=11646\n",
    "media_ids_to_add = [7139855, 7139911, 7139287, 7139856, 7143660, 7144053, 7140201, 7142111, 7143767, \n",
    "             7142952, 7143686, 3267023, 3266573, 3266744, 3251543, 3251665, 3251754, 3253943, \n",
    "             3256361, 3265129, 3268157, 3264603, 7055817, 7056643, 7057201, 7057433, 7057206,\n",
    "             7062009, 7062048, 7081110, 7081604, 7087512, 7087212, 7090604, 7092440, 7087588, 7094478,\n",
    "                    7087924, 7108698]\n",
    "sq_annotator.add_media_to_collection(media_collection_id, media_ids_to_add)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14be7d26aa5f17e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(set(media_ids).intersection(set(excluded_media)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20c49a6bf7289ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Create annotation set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9efb97283673e41f"
  },
  {
   "cell_type": "code",
   "source": [
    "media_collection_id = 11592 #Handfish Train Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a7c559a59764b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "* New annotation set (like other annotation sets?)\n",
    "* Add annotations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6016538a1721753d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Get label_scheme_id\n",
    "label_scheme_id = 7\n",
    "label_scheme_ids = list(set([a['label']['label_scheme_id'] for a in annotation_list]))\n",
    "print(label_scheme_ids)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfda28c35701f721",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "annotation_set_id = sq_annotator.create_annotation_set(name, description, media_collection_id, label_scheme_id, group_id=group_id)\n",
    "print(annotation_set_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8ff84e6d9aa0114",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Add annotations\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "698fa7dc0019c948"
  },
  {
   "cell_type": "code",
   "source": [
    "# Use this if you're not creating a new media_collection and annotation set\n",
    "annotation_set_id = annotation_list[0]['annotation_set_id']\n",
    "media_collection_id = dataset.squidle_connection.sqapi.get(f\"/api/annotation_set/{annotation_set_id}\").execute().json()\n",
    "#media_collection_id = media_collection_id['media_collection']['id']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "698775d02402cc72",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Using media_collection {media_collection_id} and annotation_set {annotation_set_id}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19f92ba1468a422e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#media_collection_id = 11598\n",
    "#annotation_set_id = Nonez"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e0b78323f2a5689",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sq_annotator.add_annotations_to_annotation_set(annotation_set_id, media_collection_id, annotation_list,\n",
    "                                               label_scheme_id=label_scheme_id)\n",
    "print(\"Finished!!!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54783cbb29c8c2c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Steps to add annotations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccda598610bac3f1"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sqapi.media import SQMediaObject\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import cv2\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1090a236f1c11709",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sam_checkpoint = \"../../segmentAnything/checkpoints/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "device = \"cuda\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f29f3233994e170",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "request = sq_annotator.sqapi.get(\"/api/media\",\n",
    "                         page=1, results_per_page=5000)\n",
    "request.filter(name=\"media_collection_media\", op=\"any\",\n",
    "               val={'name': \"media_collection_id\", 'op': 'eq', 'val': media_collection_id})\n",
    "media_data = request.execute().json()['objects']\n",
    "media_lookup = {m['id']: m for m in media_data}\n",
    "\n",
    "# Create a simple code lookup based on annotation labels.\n",
    "# todo: make this robust to different label schemes\n",
    "label_set = list(\n",
    "    set([a['label']['id'] for a in annotation_list]))\n",
    "sq_annotator.code2label = {l: {'id': l} for l in label_set}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a889ff4b2e02f80",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "annotation_media_id_dict[7769497][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1eaf166c1be60759",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for a in annotation_list:\n",
    "    # Get the point and media_obj from the annotation\n",
    "    annotation = annotation_media_id_dict[a['point']['media_id']][0]\n",
    "    point = annotation['point']\n",
    "    get_contours = False\n",
    "    if annotation['annotation_set_id'] != annotation_set_id:\n",
    "        get_contours = True\n",
    "    else:\n",
    "        if 'data' in point and 'polygon' in point['data']:\n",
    "            polygon = point['data']['polygon']\n",
    "            if len(polygon) == 4:\n",
    "                get_contours = True\n",
    "    if get_contours:\n",
    "        m = media_lookup[point['media_id']]\n",
    "        media_url = m.get('path_best')\n",
    "        media_type = m.get(\"media_type\", {}).get(\"name\")\n",
    "        mediaobj = SQMediaObject(media_url, media_type=media_type, media_id=m.get('id'))\n",
    "        if not mediaobj.is_processed:\n",
    "            orig_image = mediaobj.data()\n",
    "        width = mediaobj.width\n",
    "        height = mediaobj.height\n",
    "        x = int(point.get('x') * width)\n",
    "        y = int(point.get('y') * height)\n",
    "        label = annotation['label']['id']\n",
    "\n",
    "        # SAM\n",
    "        predictor = SamPredictor(sam)\n",
    "        predictor.set_image(orig_image)\n",
    "        input_point = np.array([[x, y]])\n",
    "        input_box = None\n",
    "        if 'data' in point and 'polygon' in point['data']:\n",
    "            polygon = point['data']['polygon']\n",
    "            if len(polygon) == 4:\n",
    "                input_box = dataset.get_bbox_in_pixels(point.get('x'), point.get('y'), polygon, width, height, buffer=0.01)\n",
    "                input_box[2] = input_box[0] + input_box[2]\n",
    "                input_box[3] = input_box[1] + input_box[3]\n",
    "                input_box = np.array(input_box)\n",
    "\n",
    "        input_label = np.array([label])\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            box=input_box,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        imgray = masks[0, :, :].astype(np.uint8)*255\n",
    "        contours, _ = cv2.findContours(imgray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1) #, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "        polygons = []\n",
    "\n",
    "        polygons = []\n",
    "        for obj in contours:\n",
    "            for c in obj:\n",
    "                coords = []\n",
    "                coords.append(int(c[0][0]))\n",
    "                coords.append(int(c[0][1]))\n",
    "                polygons.append(coords)\n",
    "\n",
    "\n",
    "        likelihood = annotation.get('likelihood', 1.0)\n",
    "        likelihood = 1.0 if likelihood is None else likelihood\n",
    "\n",
    "        # Create a new point in the annotation set and add it.\n",
    "        point_data = sq_annotator.create_annotation_label_point_px(annotation['label']['id'],\n",
    "                                                  likelihood=likelihood, \n",
    "                                                  comment=annotation['comment'],\n",
    "                                                  row=x, col=y, width=width, height=height,\n",
    "                                                  polygon=polygons,\n",
    "                                                  t=point['t'])\n",
    "        point_data['annotation_set_id'] = annotation_set_id\n",
    "        point_data['media_id'] = mediaobj.id\n",
    "        if isinstance(point_data.get('annotation_label'), dict):\n",
    "            point_data['annotation_label']['annotation_set_id'] = annotation_set_id\n",
    "\n",
    "        # Create and post point dictionary with annotation_set, media and label data.\n",
    "        if annotation['annotation_set_id'] == annotation_set_id:\n",
    "            # Add contour polygon if there isn't one.\n",
    "            print(polygons)\n",
    "            print(input_box)\n",
    "            print(annotation['id'], annotation['point']['media_id'], annotation['point']['id'], annotation['comment'])\n",
    "            last_annotation = annotation\n",
    "            \n",
    "        else:\n",
    "            sq_annotator.sqapi.post(\"/api/point\", json_data=point_data).execute()\n",
    "            print(point_data)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28c6712c3e4c267",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for annotation in annotation_list:\n",
    "    # Get the point and media_obj from the annotation\n",
    "    point = annotation['point']\n",
    "    get_contours = False\n",
    "    if annotation['annotation_set_id'] != annotation_set_id:\n",
    "        get_contours = True\n",
    "    else:\n",
    "        if 'data' in point and 'polygon' in point['data']:\n",
    "            polygon = point['data']['polygon']\n",
    "            if len(polygon) == 4:\n",
    "                get_contours = True\n",
    "    if get_contours:\n",
    "        m = media_lookup[point['media_id']]\n",
    "        media_url = m.get('path_best')\n",
    "        media_type = m.get(\"media_type\", {}).get(\"name\")\n",
    "        mediaobj = SQMediaObject(media_url, media_type=media_type, media_id=m.get('id'))\n",
    "        if not mediaobj.is_processed:\n",
    "            orig_image = mediaobj.data()\n",
    "        width = mediaobj.width\n",
    "        height = mediaobj.height\n",
    "        x = int(point.get('x') * width)\n",
    "        y = int(point.get('y') * height)\n",
    "        label = annotation['label']['id']\n",
    "\n",
    "\n",
    "        likelihood = annotation.get('likelihood', 1.0)\n",
    "        likelihood = 1.0 if likelihood is None else likelihood\n",
    "\n",
    "        # Create a new point in the annotation set and add it.\n",
    "        point_data = sq_annotator.create_annotation_label_point_px(annotation['label']['id'],\n",
    "                                                                   likelihood=likelihood,\n",
    "                                                                   comment=annotation['comment'],\n",
    "                                                                   row=x, col=y, width=width, height=height,\n",
    "                                                                   polygon=polygon,\n",
    "                                                                   t=point['t'])\n",
    "        point_data['annotation_set_id'] = annotation_set_id\n",
    "        point_data['media_id'] = mediaobj.id\n",
    "        if isinstance(point_data.get('annotation_label'), dict):\n",
    "            point_data['annotation_label']['annotation_set_id'] = annotation_set_id\n",
    "\n",
    "        # Create and post point dictionary with annotation_set, media and label data.\n",
    "        if annotation['annotation_set_id'] == annotation_set_id:\n",
    "            # Add contour polygon if there isn't one.\n",
    "            print(polygons)\n",
    "            print(input_box)\n",
    "            print(annotation['id'], annotation['point']['media_id'], annotation['point']['id'], annotation['comment'])\n",
    "            last_annotation = annotation\n",
    "            response = sq_annotator.sqapi.patch(f\"/api/annotation/8875137\", json_data={'pixels': point_data['pixels']}).execute().json()\n",
    "            print(response)\n",
    "\n",
    "        else:\n",
    "            sq_annotator.sqapi.post(\"/api/point\", json_data=point_data).execute()\n",
    "            print(point_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46d102d00d3c367",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset.squidle_connection.sqapi.get(\"api/annotation/8877749\").execute().json())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fc148fa212eb36c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "response = sq_annotator.sqapi.patch(f\"/api/annotation/8875137\", json_data={'pixels': point_data['pixels']}).execute().json()\n",
    "print(response)\n",
    "response = sq_annotator.sqapi.patch(f\"/api/annotation/8875137\", json_data={'pixels': point_data['pixels']}).execute().json()\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67b20574a4cc99a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "response = sq_annotator.sqapi.post(f\"/api/annotation\", json_data=point_data).execute().json()\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a188840edb3d38d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "scaled_polygon = []\n",
    "for c in point_data['pixels']['polygon']:\n",
    "    scaled_coord = []\n",
    "    scaled_coord.append(c[0]/point_data['pixels']['width'])\n",
    "    scaled_coord.append(c[1]/point_data['pixels']['height'])\n",
    "    scaled_polygon.append(scaled_coord)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ce7938778a327a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "del point_data['annotation_label']\n",
    "del point_data['t']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c352faae7a573606",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "response = sq_annotator.sqapi.get(f\"/api/point/8720499\").execute()\n",
    "print(response.json())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c1dd4676235a5b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(point_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3304badcfaecd202",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "response = sq_annotator.sqapi.patch(f\"/api/point/8717893\", json_data={'polygon': scaled_polygon}).execute().json()\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44393dd8e3cfe0b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(scaled_polygon)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be64ccca3b73d7a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get media and pose details for plotting\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea2bfcd2ec4bb3c"
  },
  {
   "cell_type": "code",
   "source": [
    "request = dataset.sqapi.get(\"/api/media\",\n",
    "                         page=1, results_per_page=500)\n",
    "request.filter(name=\"media_collection_media\", op=\"any\", val={'name': \"media_collection_id\", 'op': 'eq', 'val': media_collection_id})\n",
    "media_data = request.execute().json()['objects']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14c5496328dc2c6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for md in media_data:\n",
    "    request = dataset.sqapi.get(\"/api/pose\",\n",
    "                                page=1, results_per_page=500)\n",
    "    request.filter(name=\"media_id\", op=\"eq\", val=md['id'])\n",
    "    results = request.execute().json()\n",
    "    md['pose'] = results['objects']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "231589cbe1401c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6469ee4c1ea7e2bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "output = []\n",
    "for md in media_data:\n",
    "    pose = md['pose'][0]\n",
    "    output.append([md['id'],pose['campaign']['key'], pose['deployment']['id'],pose['dep'],pose['lat'],pose['lon']])\n",
    "df = pd.DataFrame(output, columns=['id','campaign', 'deployment', 'dep', 'lat', 'lon'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaef09aaf23fbe6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sns.swarmplot(data=df, x=\"lon\", y=\"lat\", hue=\"campaign\", palette=\"bright\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2131e9916b9b331",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract bot handfish annotations\n",
    "\n",
    "### Query to retrieve annotations for user, label and needs_review flag\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "396a1485565dd48b"
  },
  {
   "cell_type": "code",
   "source": [
    "# Query\n",
    "endpoint = '/api/annotation'\n",
    "filter_list1 = [dict(name=\"user\", op=\"has\", val=dict(name=\"username\", op=\"in\", val=[\"acfrbot\", \"hdoi5324\"])),\n",
    "               dict(name=\"label\", op=\"has\", val=dict(name=\"id\", op=\"eq\", val=\"13450\")),\n",
    "               dict(name=\"needs_review\", op=\"eq\", val=True)]\n",
    "filter_list3 = [dict(name=\"user\", op=\"has\", val=dict(name=\"username\", op=\"in\", val=[\"hdoi5324\"])),\n",
    "                dict(name=\"label\", op=\"has\", val=dict(name=\"id\", op=\"eq\", val=\"13450\")),\n",
    "                dict(name=\"needs_review\", op=\"eq\", val=False),\n",
    "                dict(name=\"annotation_set_id\", op=\"in\", val=[14174])]\n",
    "filter_list2 = [dict(name=\"user\", op=\"has\", val=dict(name=\"username\", op=\"not_in\", val=[\"acfrbot\", \"hdoi5324\"])),\n",
    "                dict(name=\"label\", op=\"has\", val=dict(name=\"id\", op=\"eq\", val=\"13450\"))]\n",
    "objs = []\n",
    "\n",
    "objs = squidle_connection.recursive_get(endpoint, filter_list1)\n",
    "objs += squidle_connection.recursive_get(endpoint, filter_list2)\n",
    "objs += squidle_connection.recursive_get(endpoint, filter_list3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc0687ebe68823e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "annotation_list = objs\n",
    "unique_annotations = set([a['point']['media_id'] for a in annotation_list])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bd7982fcffcdade",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Find duplication annotations on media items\n",
    "from collections import defaultdict\n",
    "ann_dict = defaultdict(list)\n",
    "keys = set()\n",
    "for a in objs:\n",
    "    media_id = a['point']['media_id']\n",
    "    is_point = a['point'].get('x') is not None\n",
    "    if is_point:\n",
    "        ann_dict[media_id].append(a)\n",
    "\n",
    "# Iterate through and create list of oldest annotation.\n",
    "new_annotation_list = []\n",
    "for media_id, a_list in ann_dict.items():\n",
    "    oldest_ann_id = min([a['id'] for a in a_list]) \n",
    "    oldest_ann = [a for a in a_list if a['id'] == oldest_ann_id]\n",
    "    new_annotation_list.append(oldest_ann[0])\n",
    "    \n",
    "annotation_list = new_annotation_list\n",
    "media_ids = ann_dict.keys()\n",
    "objs = new_annotation_list\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e8b22ff20c4e74a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert into dataframe and save"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7274575ab01e73c3"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "output = []\n",
    "annotation_set_dir = {}\n",
    "top_col_names = ['annotation_set_id', 'color', 'comment', 'created_at', 'data', 'id', 'label', 'likelihood', 'needs_review', 'object_id', 'parent_id', 'point', 'suggested_tags', 'tags', 'timestamp', 'updated_at', 'user']\n",
    "cols_to_ignore = ['data', 'label', 'point', 'tags', 'suggested_tags', 'user', 'color', 'comment']\n",
    "\n",
    "top_col_names = [item for item in top_col_names if item not in cols_to_ignore ]\n",
    "label_col_names = ['id', 'label_scheme_id', 'name']\n",
    "point_col_names = ['id', 'media_id', 't', 'x', 'y']\n",
    "media_col_names = ['deployment_id', 'key', 'path_best', 'path_best_thm']\n",
    "pose_col_names = ['alt', 'dep', 'lat', 'lon', 'timestamp']\n",
    "for r in objs:\n",
    "    # Ignore annotations with no point\n",
    "    if r['point']['x'] is not None:\n",
    "        out = []\n",
    "        for top_cn in top_col_names:\n",
    "            out.append(r[top_cn])\n",
    "        for label_cn in label_col_names:\n",
    "            out.append(r['label'].get(label_cn))\n",
    "        for point_cn in point_col_names:\n",
    "            out.append(r['point'].get(point_cn))    \n",
    "        media_obj = sq_annotator.sqapi.get(f\"/api/media/{r['point']['media_id']}\").execute().json()\n",
    "        for media_cn in media_col_names:\n",
    "            out.append(media_obj.get(media_cn))\n",
    "        for pose_cn in pose_col_names:\n",
    "            out.append(media_obj[\"pose\"].get(pose_cn))\n",
    "        out.append(r['user']['username'])\n",
    "        out.append(media_obj['deployment']['timestamp'])\n",
    "        out.append(media_obj['deployment']['campaign']['name'])\n",
    "        out.append(media_obj['deployment']['name'])\n",
    "        \n",
    "        # Annotation set details\n",
    "        annotation_set = annotation_set_dir.get(r['annotation_set_id'], None)\n",
    "        if annotation_set is None:\n",
    "            annotation_set = sq_annotator.sqapi.get(f\"/api/annotation_set\", [dict(name=\"id\", op=\"eq\", val= r['annotation_set_id'])]).execute().json()\n",
    "            if len(annotation_set['objects']) == 1:\n",
    "                annotation_set = annotation_set['objects'][0]\n",
    "                annotation_set_dir[r['annotation_set_id']] = annotation_set    \n",
    "            else:\n",
    "                print(f\"Can't find annotation set {r['annotation_set_id']}\")\n",
    "                continue\n",
    "        annotation_set_name = annotation_set['name']\n",
    "        if annotation_set['parent_id'] is not None:\n",
    "            parent_annotation_set = annotation_set_dir.get(annotation_set['parent_id'], None)\n",
    "            if parent_annotation_set is None:\n",
    "                parent_annotation_set = sq_annotator.sqapi.get(f\"/api/annotation_set/{annotation_set['parent_id']}\").execute().json()\n",
    "                annotation_set_dir[annotation_set['parent_id']] = parent_annotation_set\n",
    "            annotation_set_name = f\"{annotation_set_name} ({parent_annotation_set['name']})\"\n",
    "            \n",
    "        out.append(annotation_set_name)\n",
    "        out.append(annotation_set['media_collection']['name'])\n",
    "        output.append(out)\n",
    "\n",
    "label_col_names[0] = 'label_id'\n",
    "point_col_names[0] = 'point_id'\n",
    "column_names = top_col_names+label_col_names+point_col_names+media_col_names+pose_col_names+['username', 'deployment_timestamp', 'campaign', 'deployment_name', 'annotation_set_name', 'media_collection_name']\n",
    "df = pd.DataFrame(output, columns=column_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dd28f836ce212fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate thumbnails and store\n",
    "import os\n",
    "from PIL import Image\n",
    "from datasets.squidle_data import get_bbox_in_pixels, get_bbox_from_point_in_pixels\n",
    "from sqapi.media import SQMediaObject\n",
    "import cv2\n",
    "\n",
    "base_dir = os.path.join(os.getcwd(), \"annotation_map\")\n",
    "ann_thumbnail_dir = os.path.join(base_dir, \"annotation_thumbnails\")\n",
    "annotations = objs\n",
    "\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "os.makedirs(ann_thumbnail_dir, exist_ok=True)\n",
    "no_point_annotations = []\n",
    "# Loop through annotation and generate thumbnail\n",
    "for a in annotations:\n",
    "    # Get image\n",
    "    m = sq_annotator.sqapi.get(f\"/api/media/{a['point']['media_id']}\").execute().json()\n",
    "    ann_thumbnail_file = f\"{m['key']}_{a['id']}.jpg\"\n",
    "    if not os.path.exists(os.path.join(ann_thumbnail_dir, ann_thumbnail_file)):\n",
    "        point = a['point']\n",
    "        if point['x'] is not None:\n",
    "            media_url = m.get('path_best')\n",
    "            media_type = m.get(\"media_type\", {}).get(\"name\")\n",
    "            mediaobj = SQMediaObject(media_url, media_type=media_type, media_id=m.get('id'))    \n",
    "            print(f\"trying {media_url}\")\n",
    "            orig_image = mediaobj.data()\n",
    "            img = mediaobj.data(Image.fromarray(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)))  # convert to PIL Image\n",
    "            polygon_ann = len(point['data'].get('polygon', [])) >= 3\n",
    "        \n",
    "            # Bbox annotation\n",
    "            bbox = None\n",
    "            if polygon_ann:\n",
    "                bbox = get_bbox_in_pixels(point['x'],\n",
    "                                               point['y'],\n",
    "                                               point['data']['polygon'],\n",
    "                                               img.size[0],\n",
    "                                               img.size[1])\n",
    "                polygon_in_px = [[int((p[0] + point['x']) * img.size[0]), int((p[1] + point['y']) * img.size[1])]\n",
    "                                 for p in point['data']['polygon']]\n",
    "            elif not polygon_ann:\n",
    "                # Point annotation estimation around point.  Rough\n",
    "                # todo: Change this to some other estimation method\n",
    "                bbox = get_bbox_from_point_in_pixels(point['x'],\n",
    "                                                          point['y'],\n",
    "                                                          img.size[0],\n",
    "                                                          img.size[1])\n",
    "            # Crop image\n",
    "            bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "            ann_thumbnail = img.crop(bbox)\n",
    "            ann_thumbnail.save(os.path.join(ann_thumbnail_dir, ann_thumbnail_file))\n",
    "        else:\n",
    "            no_point_annotations.append(a)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "771998e15f56838e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "os.path.exists(os.path.join(ann_thumbnail_dir, ann_thumbnail_file))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2e6181a9f823100",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "os.path.join(ann_thumbnail_dir, ann_thumbnail_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acddb836d977c6c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv(\"handfish_detections.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8021b18264f9abbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import os\n",
    "import folium\n",
    "print( folium.__version__)\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "from folium import IFrame\n",
    "from folium.plugins import FloatImage\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import branca\n",
    "#sns.swarmplot(data=df, x=\"lon\", y=\"lat\", hue=\"deployment_id\", palette=\"bright\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5312fa165aa2c028",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate html file from dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c91a2071c3e109f"
  },
  {
   "cell_type": "code",
   "source": [
    "base_dir = os.path.join(os.getcwd(), \"annotation_map\")\n",
    "ann_thumbnail_dir = os.path.join(base_dir, \"annotation_thumbnails\")\n",
    "centre = ((df.lat.max() + df.lat.min())/2, (df.lon.max() + df.lon.min())/2)\n",
    "map = folium.Map(location=centre, zoom_start=8, control_scale=True, max_zoom=25, tiles=\"CartoDB Voyager\")\n",
    "colors = [\n",
    "    'red',\n",
    "    'blue',\n",
    "    'gray',\n",
    "    'darkred',\n",
    "    'lightred',\n",
    "    'orange',\n",
    "    'beige',\n",
    "    'green',\n",
    "    'darkgreen',\n",
    "    'lightgreen',\n",
    "    'darkblue',\n",
    "    'lightblue',\n",
    "    'purple',\n",
    "    'darkpurple',\n",
    "    'pink',\n",
    "    'cadetblue',\n",
    "    'lightgray',\n",
    "    'black',\n",
    "    'red',\n",
    "    'blue',\n",
    "    'gray',\n",
    "    'darkred',\n",
    "    'lightred',\n",
    "    'orange',\n",
    "    'beige',\n",
    "    'green',\n",
    "    'darkgreen',\n",
    "    'lightgreen',\n",
    "    'darkblue',\n",
    "    'lightblue',\n",
    "    'purple',\n",
    "    'darkpurple',\n",
    "    'pink',\n",
    "    'cadetblue',\n",
    "    'lightgray',\n",
    "    'black',\n",
    "]\n",
    "\n",
    "legend_html = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"\n",
    "    position: fixed;\n",
    "    bottom: 50px;\n",
    "    right: 50px;\n",
    "    width: 150px;\n",
    "    height: 100px;\n",
    "    z-index:9999;\n",
    "    font-size:14px;\n",
    "    \">\n",
    "    <p>Source of Detection</p>\n",
    "    <p><i class=\"fa-solid fa-eye\"></i>&emsp;Human</p>\n",
    "    <p><i class=\"fa-solid fa-cogs\"></i>&emsp;AI</p>\n",
    "</div>\n",
    "<div style=\"\n",
    "    position: fixed;\n",
    "    bottom: 50px;\n",
    "    right: 50px;\n",
    "    width: 150px;\n",
    "    height: 100px;\n",
    "    z-index:9998;\n",
    "    font-size:14px;\n",
    "    background-color: #ffffff;\n",
    "    filter: blur(8px);\n",
    "    -webkit-filter: blur(8px);\n",
    "    opacity: 0.7;\n",
    "    \">\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "legend = branca.element.MacroElement()\n",
    "legend._template = branca.element.Template(legend_html)\n",
    "map.get_root().add_child(legend)\n",
    "\n",
    "g_idx = 0\n",
    "cogs_data, eye_data = [], []\n",
    "\n",
    "#             <img src=\\\"\"\"\" + row.path_best_thm + \"\"\"\\\" alt=\\\"\"\"\" + row.key + \"\"\"\\\"> <br>\n",
    "\n",
    "for g in df.groupby(\"deployment_name\"):\n",
    "\n",
    "    marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "    #group_1 = folium.FeatureGroup(g[0]).add_to(map)\n",
    "    for i, row in g[1].iterrows():\n",
    "        point = (row.lat, row.lon)\n",
    "        html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "\n",
    "            Depth (m): \"\"\" + f\"{row.dep:.2f}\" + \"\"\"  <br>\n",
    "            User: \"\"\" + row.username + \"\"\" <br>\n",
    "            <img src=\\\"\"\"\" + f\"https://annotation-map.s3.ap-southeast-2.amazonaws.com/annotation_thumbnails/{row.key}_{row.id}.jpg\" + \"\"\"\\\" alt=\\\"\"\"\" + row.key + \"\"\"\\\" width=\"200\"> <br>\n",
    "            Deployment Timestamp: \"\"\" + row.deployment_timestamp + \"\"\" <br>\n",
    "            Deployment:  \"\"\" + row.deployment_name + \"\"\" <br>\n",
    "            Campaign:  \"\"\" + row.campaign + \"\"\" <br>\n",
    "            Annotation Set: \"\"\" + row.annotation_set_name + \"\"\" <br>\n",
    "            Media Collection: \"\"\" + row.media_collection_name + \"\"\" <br>\n",
    "            <a href=\\\"\"\"\" + row.path_best + \"\"\"\\\">Full image \"\"\" + row.key + \"\"\"</a> <br>\n",
    "            \"\"\"\n",
    "   #html = html_template(row.dep, row.username, row.deployment_timestamp, row.path_best_thm, row.key, row.id, row.id )\n",
    "        \n",
    "        #print(html)\n",
    "        html = folium.Html(html, script=True)\n",
    "        #iframe = branca.element.IFrame(html=html, width=500, height=300)\n",
    "        popup = folium.Popup(html, max_width=300)\n",
    "\n",
    "        # icons from https://fontawesome.com/v4/icons/\n",
    "        if row.username in ['acfrbot', 'hdoi5324']:\n",
    "            icon = \"cogs\"\n",
    "            cogs_data.append([row.lat, row.lon, 1])\n",
    "        else:\n",
    "            icon = \"eye\"\n",
    "            eye_data.append([row.lat, row.lon, 1])\n",
    "\n",
    "        #icon = \"cogs\" if row.username in ['acfrbot', 'hdoi5324'] else \"eye\"\n",
    "        folium.Marker(point, icon=folium.Icon(colors[g_idx], icon=icon, prefix=\"fa\"), tooltip=f\"{row.deployment_name},\\n {row.campaign}\", popup=popup, lazy=True).add_to(marker_cluster)\n",
    "        \n",
    "    g_idx += 1\n",
    "#folium.LayerControl().add_to(map)\n",
    "\n",
    "#display(map)\n",
    "#HeatMap(eye_data).add_to(map)\n",
    "map.save(os.path.join(base_dir, \"handfish_detection_map.html\"))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe9c51d050d93f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Test case\n",
    "# \n",
    "import folium\n",
    "print( folium.__version__)\n",
    "import branca\n",
    "print(branca.__version__)\n",
    "\n",
    "\n",
    "map = folium.Map(location=[-42., 147], zoom_start=7)\n",
    "point = (-42., 147.)\n",
    "id = 8800753\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "            <p>\n",
    "            Link to annotation thumbnails at https://squidle.org/iframe/api/annotation?q=%7B%22filters%22:[%7B%22name%22:%22id%22,%22op%22:%22eq%22,%22val%22:\"\"\" + str(id) + \"\"\"%7D]%7D&disposition=%22inline%22&page=1&results_per_page=10&template=models/annotation/list_thumbnails.html&nologin=true&include_link=false </br> \n",
    "            </p>\n",
    "            <iframe id=\"myIFrame\" src= https://squidle.org/iframe/api/annotation?q=%7B%22filters%22:[%7B%22name%22:%22id%22,%22op%22:%22eq%22,%22val%22:\"\"\" + str(id) + \"\"\"%7D]%7D&disposition=%22inline%22&page=1&results_per_page=10&template=models/annotation/list_thumbnails.html&nologin=true&include_link=false  width=%22500%22 height=%22300%22 frameborder=%220%22>\n",
    "            </html>\n",
    "            \"\"\"\n",
    "html = folium.Html(html, script=True)\n",
    "iframe = branca.element.IFrame(html=html, width=500, height=300)\n",
    "popup = folium.Popup(iframe, max_width=500)\n",
    "\n",
    "# icons from https://fontawesome.com/v4/icons/\n",
    "folium.Marker(point, tooltip=f\"click here\", popup=popup, lazy=True).add_to(map)\n",
    "map.save(\"test_handfish.html\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d71d958efa63179",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tidy up phantom points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ab9fa8fdac31482"
  },
  {
   "cell_type": "code",
   "source": [
    "### Config and squidle access setup\n",
    "acfrbot_userid = 1433\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26a8617f7e7d8ea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "config = \"squidle_hand_target.yaml\"\n",
    "abs_config_dir=os.path.abspath(\"../config/dataset\")\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    opt = compose(config_name=config)\n",
    "OmegaConf.set_struct(opt, False)\n",
    "\n",
    "dataset = SquidleData(opt, semi_supervised=True)\n",
    "sq_annotator = SquidleAnnotator(api_key=opt.api_token, host=opt.url)\n",
    "sqapi = SQAPI(api_key=opt.annotate_api_token, host=opt.url)\n",
    "squidle_connection = SquidleConnection(sqapi=sqapi)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebfdbe723bdc491a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Get annotations for annotation set\n",
    "ann_set_to_clean = 14146\n",
    "ann_endpoint = '/api/annotation'\n",
    "filter_list1 = [dict(name=\"annotation_set_id\", op=\"in\", val=[ann_set_to_clean])]\n",
    "\n",
    "all_ann = squidle_connection.recursive_get(ann_endpoint, filter_list=filter_list1)\n",
    "filter_list1 = [dict(name=\"annotation_set\", op=\"has\", val=dict(name=\"parent_id\", op=\"in\", val=[ann_set_to_clean]))]\n",
    "all_child_ann = squidle_connection.recursive_get(ann_endpoint, filter_list=filter_list1)\n",
    "# Get annotations for annotation set\n",
    "endpoint = '/api/point'\n",
    "filter_list1 = [dict(name=\"annotation_set_id\", op=\"eq\", val=ann_set_to_clean)]\n",
    "all_point = squidle_connection.recursive_get(endpoint, filter_list=filter_list1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddcad8a60cc9ba1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(Counter([a['annotation_set_id'] for a in all_ann]))\n",
    "print(Counter([a['annotation_set_id'] for a in all_child_ann]))\n",
    "print(Counter([p['annotation_set_id'] for p in all_point]))\n",
    "print(Counter([a['point']['annotation_set_id'] for a in all_ann]))\n",
    "print(Counter([a['point']['annotation_set_id'] for a in all_child_ann]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "609a52d88d203de3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "point_dict = {p['id']:p for p in all_point}\n",
    "ann_dict = {a['point']['id']: a for a in all_ann + all_child_ann}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bcf3f550154e8eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Delete points with no annotations\n",
    "phantom_points = list(set(point_dict.keys()).difference(ann_dict.keys()))\n",
    "for p_id in phantom_points[3:]:\n",
    "    point = point_dict[p_id]\n",
    "    if ann_dict.get(p_id, None) is None and len(point['annotations']) == 0:\n",
    "        response = squidle_connection.delete(f'/api/point/{p_id}').execute()\n",
    "        print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0c936e7a0b49e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Delete annotations with no label generated by acfrbot\n",
    "# \n",
    "for a in all_ann[1:]:\n",
    "    if a.get('label', None) is None and a['user']['username'] == 'acfrbot' and a['annotation_set_id'] == ann_set_to_clean:\n",
    "        a_id = a[\"id\"]\n",
    "        response = squidle_connection.delete(f'/api/annotation/{a_id}').execute()\n",
    "        print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "964578b0522da7fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "ann_dict.get(p_id, None)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c520a0b5eef29e78",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "point_endpoint = '/api/point'\n",
    "filter_list2 = [dict(name=\"annotation_set\", op=\"has\", val=dict(name=\"user_id\", op=\"in\", val=\"451\")),\n",
    "                dict(name=\"annotations\", op=\"any\", val=(dict(name=\"annotation_set_id\", op=\"eq\", val=ann_set_to_clean)))]\n",
    "test_point_2 = squidle_connection.recursive_get(point_endpoint, filter_list2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c4e4b96ec3329c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print([a['id'] for a in test_point_2])\n",
    "print([a['point']['id'] for a in test_ann])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daffd1c87ffa4cf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(Counter([a['user']['username'] for a in test_ann]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0409d7d6874a94c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(Counter([a['label']['id'] if a.get('label', None) is not None else 0 for a in test_ann]))\n",
    "print(Counter([a['point']['annotation_set_id'] for a in test_ann]))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b28334da5ab3d4c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Media collection with handfish media items\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c597190dd61f896"
  },
  {
   "cell_type": "code",
   "source": [
    "# Open media collection\n",
    "asi = 13372\n",
    "media_collection_id = dataset.squidle_connection.sqapi.get(f\"/api/annotation_set/{asi}\").execute().json()\n",
    "media_collection_id = media_collection_id['media_collection']['id']\n",
    "media_endpoint = '/api/media'\n",
    "filter_list1 = [dict(name=\"media_collection_media\", op=\"any\",\n",
    "                     val={'name': \"media_collection_id\", 'op': 'eq', 'val': media_collection_id})]\n",
    "\n",
    "media = squidle_connection.recursive_get(media_endpoint, filter_list=filter_list1)\n",
    "\n",
    "# Iterate through media\n",
    "adjacent_media = []\n",
    "id_buffer = 3\n",
    "for m in media:\n",
    "    # Query for media near media item\n",
    "    adj_filter = [dict(name=\"id\", op=\"gt\", val=m['id'] - id_buffer),\n",
    "                  dict(name=\"id\", op=\"lt\", val=m['id'] + id_buffer),\n",
    "                  dict(name=\"id\", op=\"!=\", val=m['id'])]\n",
    "    adjacent_media += squidle_connection.recursive_get(media_endpoint, filter_list=adj_filter)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bb786f6a9124e28",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "og_media_ids = [m['id'] for m in media]\n",
    "print(len(og_media_ids), len(set(og_media_ids)))\n",
    "adj_media_ids = [m['id'] for m in adjacent_media if m['id'] not in og_media_ids]\n",
    "keys = [m['key'] for m in adjacent_media]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8309383edd454ba1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create media_collection\n",
    "name = \"Handfish Test 15pc Dataset - adjacent images\"\n",
    "description = f\"Images before and after annotated handfish images. Select {id_buffer} images either side annotated image.  Found {len(adj_media_ids)} additional images from {len(adjacent_media)} adjacent images.\"\n",
    "media_collection_id = sq_annotator.create_media_collection(name=name, description=description)\n",
    "print(media_collection_id)\n",
    "# Add media\n",
    "# ADDING MEDIA to collection\n",
    "sq_annotator.add_media_to_collection(media_collection_id, adj_media_ids)\n",
    "print(\"Finished!!!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d452c06b2efc3b0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
